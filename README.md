# Neural Style Transfer Study - from image collections to video from VGG to diffusion

## Main Contribution
- conducted elaborate comparison experiments among different neural architectures and models, including: VGG, ResNet, AlexNet, Fast Style Transfer, Multimodal style transfer, CycleGAN, and Diffusion
- provided evaluation metrics towards 1. model performance (effectiveness for style and coherence for content) and 2. model efficiency 
based on FID, CLIP, Contour Detection, User Ranking
training time, memory allocation
fine-tuned models to generate single-image style transfer, collection style transfer and video style transfer
maintained model robustness with large images and videos

MST: https://drive.google.com/drive/folders/1TV7auFaVm9YubetFQ_EizncI8-CLVOfL?usp=sharing
