{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dj3ymUqMTzyX","executionInfo":{"status":"ok","timestamp":1702143518773,"user_tz":300,"elapsed":1273,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}},"outputId":"736a97c1-6889-4590-e036-7e68c9cfca7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip3 install omegaconf\n","!pip3 install einops\n","!pip3 install pytorch-lightning==1.7.1\n","!pip3 install torchmetrics==0.11.4\n","!pip3 install taming-transformers\n","!pip3 install kornia\n","!pip3 install git+https://github.com/openai/CLIP.git\n","!pip3 install openai-clip"],"metadata":{"id":"ibzlTDsbUj20","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d054511-10ef-41aa-f5ef-5c2d844bf05b","executionInfo":{"status":"ok","timestamp":1702143590625,"user_tz":300,"elapsed":71856,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: pytorch-lightning==1.7.1 in /usr/local/lib/python3.10/dist-packages (1.7.1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (1.23.5)\n","Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (6.0.1)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (2023.6.0)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (2.14.1)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (0.11.4)\n","Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (0.3.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (23.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.1) (4.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (3.9.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (1.59.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (3.5.1)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.1) (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.1) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.1) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.1) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.1) (2.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (4.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning==1.7.1) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning==1.7.1) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning==1.7.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->pytorch-lightning==1.7.1) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.1) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning==1.7.1) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.*->pytorch-lightning==1.7.1) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning==1.7.1) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->pytorch-lightning==1.7.1) (3.2.2)\n","Requirement already satisfied: torchmetrics==0.11.4 in /usr/local/lib/python3.10/dist-packages (0.11.4)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.4) (1.23.5)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.4) (2.1.0+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.4) (23.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==0.11.4) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics==0.11.4) (1.3.0)\n","Requirement already satisfied: taming-transformers in /usr/local/lib/python3.10/dist-packages (0.0.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (0.16.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (1.23.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (4.66.1)\n","Requirement already satisfied: omegaconf>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (2.3.0)\n","Requirement already satisfied: pytorch-lightning>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (1.7.1)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0.0->taming-transformers) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0.0->taming-transformers) (6.0.1)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.8->taming-transformers) (2023.6.0)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.8->taming-transformers) (2.14.1)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.8->taming-transformers) (0.11.4)\n","Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.8->taming-transformers) (0.3.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.8->taming-transformers) (23.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.8->taming-transformers) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->taming-transformers) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->taming-transformers) (9.4.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.8->taming-transformers) (3.9.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (1.59.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (3.5.1)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (3.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->taming-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->taming-transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->taming-transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->taming-transformers) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->taming-transformers) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->taming-transformers) (1.3.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.8->taming-transformers) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.8->taming-transformers) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.8->taming-transformers) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.8->taming-transformers) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.8->taming-transformers) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.0.8->taming-transformers) (4.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (1.3.1)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->pytorch-lightning>=1.0.8->taming-transformers) (3.2.2)\n","Requirement already satisfied: kornia in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (23.2)\n","Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-3qyavpow\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-3qyavpow\n","  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu118)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.12)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n","Requirement already satisfied: openai-clip in /usr/local/lib/python3.10/dist-packages (1.0.1)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from openai-clip) (6.1.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from openai-clip) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-clip) (4.66.1)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->openai-clip) (0.2.12)\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/CIS581/InST"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Rt0t3hPT8fR","executionInfo":{"status":"ok","timestamp":1702143590625,"user_tz":300,"elapsed":14,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}},"outputId":"66a08e6c-9a1a-473d-949c-03e206e4ac83"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/CIS581/InST'\n","/content\n"]}]},{"cell_type":"code","source":["from evaluation.clip_eval import CLIPEvaluator\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import clip\n","from PIL import Image\n","import PIL\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","clipEvaluator = CLIPEvaluator(device)\n","\n","def load_img(path):\n","    image = Image.open(path).convert(\"RGB\")\n","    w, h = image.size\n","    print(f\"loaded input image of size ({w}, {h}) from {path}\")\n","    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n","    image = image.resize((512, 512), resample=PIL.Image.LANCZOS)\n","    image = np.array(image).astype(np.float32) / 255.0\n","    image = image[None].transpose(0, 3, 1, 2)\n","    image = torch.from_numpy(image)\n","    return 2.*image - 1."],"metadata":{"id":"Vr3slVoFUFKT","colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"status":"error","timestamp":1702143590625,"user_tz":300,"elapsed":10,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}},"outputId":"ef571084-d473-4f07-8d2d-5969cebbb67d"},"execution_count":10,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-bc4098677946>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_eval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCLIPEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluation'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["style = load_img('data/andre.jpg')\n","content = load_img('data/IMG_1581.JPG')\n","style2 = load_img('data/monet.jpg')\n","generated = load_img('outputs/img2img-samples/IMG_1581-*-0050.png')\n","i2i = clipEvaluator.img_to_img_similarity(style2, generated)\n","\n","print(i2i)"],"metadata":{"id":"UIk7n1irZR5l","executionInfo":{"status":"aborted","timestamp":1702143590625,"user_tz":300,"elapsed":9,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# text = 'a modern style of painting of the city'\n","# content = load_img('data/IMG_1581.JPG')\n","# generated = load_img('outputs/img2img-samples/IMG_1581-*-0050.png')\n","# t2i = clipEvaluator.txt_to_img_similarity(text, content)\n","\n","# print(t2i)"],"metadata":{"id":"i5PsPjBqbkVv","executionInfo":{"status":"aborted","timestamp":1702143590626,"user_tz":300,"elapsed":9,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from numpy import cov\n","from numpy import trace\n","from numpy import iscomplexobj\n","from numpy import asarray\n","from numpy.random import randint\n","from scipy.linalg import sqrtm\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.inception_v3 import preprocess_input\n","from keras.datasets.mnist import load_data\n","from skimage.transform import resize\n","import tensorflow as tf\n","from math import sqrt\n","import cv2\n","\n","input_shape = (256, 256, 3)\n","\n","# def scale_images(image, new_shape):\n","#   images_list = []\n","#   new_image = resize(image, new_shape, 0)\n","#   images_list.append(new_image)\n","#   return asarray(images_list)\n","\n","def calculate_fid(model, images1, images2, new_shape=input_shape): #lower is better\n","    images1_np = images1.permute(0, 2, 3, 1).cpu().numpy()\n","    images2_np = images2.permute(0, 2, 3, 1).cpu().numpy()\n","    images1_np = np.array([cv2.resize(img, (256, 256)) for img in images1_np])\n","    images2_np = np.array([cv2.resize(img, (256, 256)) for img in images2_np])\n","    images1_np = preprocess_input(images1_np)\n","    images2_np = preprocess_input(images2_np)\n","\n","    act1 = model.predict(images1_np)\n","    act2 = model.predict(images2_np)\n","    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n","    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n","    ssdiff = np.sum((mu1 - mu2) ** 2.0)\n","\n","    covmean = sqrt(sigma1*sigma2)\n","    if np.iscomplexobj(covmean):\n","        covmean = covmean.real\n","\n","    fid = ssdiff + sigma1 + sigma2 - 2.0 * covmean\n","    return fid\n","\n","IncModel = InceptionV3(include_top=False, pooling='avg', input_shape=input_shape)\n"],"metadata":{"id":"wQek1cSOc4Ua","executionInfo":{"status":"aborted","timestamp":1702143590626,"user_tz":300,"elapsed":9,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images1 = load_img('data/andre.jpg')\n","monet = load_img('data/monet.jpg')\n","modern = load_img('data/modern.jpg')\n","content = load_img('data/IMG_1581.JPG')\n","\n","images2 = load_img('outputs/img2img-samples/IMG_1581-*-0051.png')\n","images3 = load_img('outputs/img2img-samples/IMG_1581-*-0050.png')\n","fid_value = calculate_fid(IncModel, style, images3) #only style\n","print(fid_value)"],"metadata":{"id":"zh33UxKim6cm","executionInfo":{"status":"aborted","timestamp":1702143590626,"user_tz":300,"elapsed":9,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","from google.colab.patches import cv2_imshow\n","\n","content_image = cv2.imread('data/IMG_1581.JPG')\n","generated_image = cv2.imread('outputs/img2img-samples/IMG_1581-*-0050.png')\n","\n","image = cv2.resize(content_image, (512, 512))\n","img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_BINARY)\n","cv2_imshow(thresh)\n","cv2.waitKey(0)\n","cv2.imwrite('image_thres1.jpg', thresh)\n","cv2.destroyAllWindows()\n","\n","# contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n","\n","# # draw contours on the original image\n","# image_copy = image.copy()\n","# cv2.drawContours(image=image_copy, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n","\n","# # see the results\n","# cv2_imshow(image_copy)\n","# cv2.waitKey(0)\n","# cv2.imwrite('contours_none_image1.jpg', image_copy)\n","# cv2.destroyAllWindows()\n","\n","contours1, hierarchy1 = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","image_copy1 = image.copy()\n","cv2.drawContours(image_copy1, contours1, -1, (0, 255, 0), 2, cv2.LINE_AA)\n","cv2_imshow(image_copy1)\n","cv2.waitKey(0)\n","cv2.imwrite('contours_simple_image1.jpg', image_copy1)\n","cv2.destroyAllWindows()\n","\n","\n","image1 = cv2.resize(generated_image, (512, 512))\n","img_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n","\n","ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_BINARY)\n","cv2_imshow(thresh)\n","cv2.waitKey(0)\n","cv2.imwrite('image_thres1.jpg', thresh)\n","cv2.destroyAllWindows()\n","\n","contours2, hierarchy2 = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","image_copy2 = image1.copy()\n","cv2.drawContours(image_copy2, contours2, -1, (0, 255, 0), 2, cv2.LINE_AA)\n","cv2_imshow(image_copy2)\n","cv2.waitKey(0)\n","cv2.imwrite('contours_simple_image1.jpg', image_copy2)\n","cv2.destroyAllWindows()\n","\n","print(len(contours1), len(contours2))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"xnvJ1q2W__Hk","executionInfo":{"status":"error","timestamp":1702144270864,"user_tz":300,"elapsed":688,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}},"outputId":"fd73c6af-a896-4923-a784-fdfa1dc27d06"},"execution_count":11,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-3bc26a347349>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs/img2img-samples/IMG_1581-_-0044.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mimg_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"]}]},{"cell_type":"code","source":["# ----- none -----\n","\n","import cv2\n","import numpy as np\n","\n","def calculate_iou(contour1, contour2):\n","    # Create binary images from the contours\n","    img1 = np.zeros((512, 512), dtype=np.uint8)\n","    img2 = np.zeros((512, 512), dtype=np.uint8)\n","    cv2.drawContours(img1, [contour1], -1, 1, -1)\n","    cv2.drawContours(img2, [contour2], -1, 1, -1)\n","\n","    # Calculate intersection and union\n","    intersection = np.logical_and(img1, img2)\n","    union = np.logical_or(img1, img2)\n","    iou = np.sum(intersection) / np.sum(union)\n","    return iou\n","\n","def evaluate_contours(true_contours, detected_contours, iou_threshold=0.5):\n","    TP, FP, FN = 0, 0, 0\n","\n","    matched = set()\n","    for d_contour in detected_contours:\n","        is_match = False\n","        for idx, t_contour in enumerate(true_contours):\n","            if calculate_iou(d_contour, t_contour) > iou_threshold and idx not in matched:\n","                TP += 1\n","                matched.add(idx)\n","                is_match = True\n","                break\n","        if not is_match:\n","            FP += 1\n","\n","    FN = len(true_contours) - len(matched)\n","\n","    precision = TP / (TP + FP) if TP + FP > 0 else 0\n","    recall = TP / (TP + FN) if TP + FN > 0 else 0\n","    f_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","    return precision, recall, f_score\n","\n","\n","precision, recall, f_score = evaluate_contours(contours2, contours1)\n","print(f\"Precision: {precision:.3f}\")\n","print(f\"Recall: {recall:.3f}\")\n","print(f\"F-score: {f_score:.3f}\")"],"metadata":{"id":"a7CEgHnTg4Ae","executionInfo":{"status":"aborted","timestamp":1702143590626,"user_tz":300,"elapsed":9,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_precision_recall(contours_a, contours_b, threshold):\n","    x = contours_a\n","    y = contours_b\n","\n","    xx = np.array(x)\n","    hits = []\n","    for yrec in y:\n","        d = np.square(xx[:,0] - yrec[0]) + np.square(xx[:,1] - yrec[1])\n","        hits.append(np.any(d < threshold*threshold))\n","    top_count = np.sum(hits)\n","\n","    try:\n","        precision_recall = top_count / len(y)\n","    except ZeroDivisionError:\n","        precision_recall = 0\n","\n","    return precision_recall, top_count, len(y)\n","\n","\n","precision_recall, top_count, length = calc_precision_recall(contours2, contours1,0.5)\n","print(f\"Precision: {precision_recall:.3f}\")\n","print(f\"Recall: {top_count:.3f}\")\n","print(f\"F-score: {length:.3f}\")"],"metadata":{"id":"skJBW96FlInZ","executionInfo":{"status":"aborted","timestamp":1702143590626,"user_tz":300,"elapsed":9,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","image1 = cv2.imread('data/modern.jpg')\n","image1 = cv2.resize(image1, (512, 512))\n","\n","img_gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n","\n","ret, thresh1 = cv2.threshold(img_gray1, 150, 255, cv2.THRESH_BINARY)\n","contours2, hierarchy2 = cv2.findContours(thresh1, cv2.RETR_TREE,\n","                                               cv2.CHAIN_APPROX_SIMPLE)\n","image_copy2 = image1.copy()\n","cv2.drawContours(image_copy2, contours2, -1, (0, 255, 0), 2, cv2.LINE_AA)\n","cv2_imshow(image_copy2)\n","cv2.waitKey(0)\n","image_copy3 = image1.copy()\n","for i, contour in enumerate(contours2): # loop over one contour area\n","   for j, contour_point in enumerate(contour): # loop over the points\n","       # draw a circle on the current contour coordinate\n","       cv2.circle(image_copy3, ((contour_point[0][0], contour_point[0][1])), 2, (0, 255, 0), 2, cv2.LINE_AA)\n","# see the results\n","cv2_imshow(image_copy3)\n","cv2.waitKey(0)\n","cv2.imwrite('contour_point_simple.jpg', image_copy3)\n","cv2.destroyAllWindows()\n","print(len(contours2))"],"metadata":{"id":"s1A1L_bID0nK","executionInfo":{"status":"aborted","timestamp":1702143590627,"user_tz":300,"elapsed":10,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from numpy import asarray\n","from numpy import expand_dims\n","from numpy import log\n","from numpy import mean\n","from numpy import exp\n","\n","# calculate the inception score for p(y|x)\n","def calculate_inception_score(p_yx, eps=1E-16):\n","    p_y = expand_dims(p_yx.mean(axis=0), 0)\n","    kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n","    sum_kl_d = kl_d.sum(axis=1)\n","    avg_kl_d = mean(sum_kl_d)\n","    is_score = exp(avg_kl_d)\n","    return is_score"],"metadata":{"id":"D3LACGzUVMBl","executionInfo":{"status":"aborted","timestamp":1702143590627,"user_tz":300,"elapsed":10,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"m-mqWtH8VgLm","executionInfo":{"status":"aborted","timestamp":1702143590627,"user_tz":300,"elapsed":9,"user":{"displayName":"Yuan Zhang","userId":"15539716428397566732"}}},"execution_count":null,"outputs":[]}]}